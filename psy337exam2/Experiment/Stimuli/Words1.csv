Cue,Answer,Shuffle,Stimuli Notes
Who was Thorndike and what did he do with puzzle boxes?,"Thorndike placed hungry cats inside a puzzle box. Eventually, the cats figured out how to get out of the puzzle box, and that particular behavior was reinforced. Cats got faster and faster (i.e., reduced their latency) at escaping from the puzzle box.",ON,bl
What is the law of effect?,Any behavior that is followed by a satisfactory outcome will be strengthened,ON,bl
What is the difference between positive and negative reinforcement?,"Positive reinforcement involves adding something pleasant; negative reinforcement involves removing something unpleasant; Importantly, BOTH forms of reinforcement strengthen behavior",ON,bl
Davis and Smith (1976) conducted a study regarding morphine in rats. What did they find?,"They found that rats will continue to press a lever to sound a buzzer (secondary reinforcer), even though the buzzer was not directly paired with a morphine reward. This highlights the power of secondary reinforcers.",ON,bl
Hammond (1980) manipulated contingency using an ABAB-reversal design. What was the main result?,"During periods of moderate contingency, rats rapidly pressed the lever; during periods of zero contingency (i.e., meaning a food reward was being delivered 50% of the time regardless of behavior), the rate of lever pressing was dramatically reduced",ON,bl
"Doughty et al., (2012) manipulated the size of the reinforcer following a lever press. What did they find?","Behavior was strengthened more following a larger reinforcer (i.e., 6 pellets of food) versus a smaller reinforcer (i.e., 1 pellet of food).",ON,bl
Miller and Dicara (1967) investigated rats and biofeedback. What did they find?,These researchers found that rats who had been given curare and could not physically move could still increase or decrease their heart rates by 20% if such a behavior was reinforced via electrical brain stimulation,ON,bl
Hollerman and Schultz (1998) investigated dopamine and reward predictability. What did they find?,"The main result was that neurons coded the reward schedule, and unpredictable rewards resulted in the biggest dopamine spikes",ON,bl
What is Response-Deprivation Theory?,"When our access to a particular behavior or resource falls below our baseline level, we will engage in behaviors to try to return to our baseline levels; An example would be if Joey usually watches 3 hours of TV per night, but can only watch 1 hour of TV today, he is more likely to finish his other tasks more efficiently to free up more time to watch TV",ON,bl
"What is the Sidman Avoidance Procedure (Sidman, 1953)?","Rat receives shocks at regular intervals, but can press a lever to delay the shock for 15 seconds. Once they learn this, there is rapid and constant lever pressing.",ON,bl
What was Anger's criticism of Sidman's Avoidance Procedure?,"Anger claimed that there is a valid CS in the Sidman Avoidance Procedure - time. Given that shock always followed a 15 second period, Anger reasoned that the rats may be using time as a CS to press the lever",ON,bl
How did Herrnstein and Hineline (1966) debunk Anger's criticism of the Sidman Avoidance Procedure?,"These researchers used the Sidman Avoidance procedure but had the shocks occur randomly instead of after a set time of 15 seconds. Even with random shocks, the rats rapidly pressed the lever to avoid shocks, suggesting that time is not a valid CS",ON,bl
What is shaping?,Reinforcement of successive approximations,ON,bl
What is the difference between forward versus backward chaining?,"Forward chaining means you start with the first behavior to be performed, then add a second, third, and so on with each practice attempt; backward chaining means you start with the last behavior to be learned, and work backwards by then adding the second to last behavior, third to last, and so on",ON,bl
What is insight learning?,When the solution to a problem tends to happen immediately and without any warning,ON,bl
"What did the Epstein et al., (1984) study show with pigeons and insight learning?",These researchers showed that pigeons cannot exhibit insight learning unless all the necessary behaviors have been previously reinforced,ON,bl
"What did Harlow (1949) investigate with ""learning sets""?","Harlow presented monkeys with two lids. Picking the correct lid resulted in reinforcement. Over time, the monkeys learned that if the first lid they chose was wrong, they could get reinforcement by picking the other lid. They only learned this rule following lots of practice with the task. This suggests that insight learning develops slowly over time (e.g., ""The Evolution of Insight"").",ON,bl
What did Skinner (1948) discover regarding superstitious pigeons?,"Skinner reinforced the pigeons every 15 seconds regardless of their behavior. The pigeons, however, believed that their actions caused the reinforcement and started engaging in ritualistic, superstitious behaviors that had no bearing on the reinforcement.",ON,bl
What is learned helplessness?,"If an animal has been previously exposed to an inescapable aversive stimulus (e.g., inescapable shocks) a sufficient number of times, the animal will eventually give up and stop trying to escape altogether (even if escape is possible)",ON,bl
What is resiliency?,"If an animal can escape an aversive stimulus initially (e.g., avoid shock), the animal will engage in a behavior to avoid the aversive stimulus. If, later on, the aversive stimulus cannot be avoided, the animal will continue trying to escape and never give up; this ""never giving up"" attitude is resiliency",ON,bl
What is a fixed ratio schedule?,"Reinforcement occurs once every X times (e.g., reinforcement occurs after every 5 lever presses)",ON,bl
What is a fixed interval schedule?,"Reinforcement occurs if a response is made within a specific unit of time (e.g., reinforcement occurs if a response is made 1 time within a 20 second window)",ON,bl
What is a variable ratio schedule?,"Reinforcement occurs once every average number of X times (e.g., reinforcement occurs once after an average of 5 lever presses)",ON,bl
What is a variable interval schedule?,"Reinforcement occurs if a response is made within an average unit of time (e.g., reinforcement occurs if a response is made once within an average of 5 seconds)",ON,bl
What is extinction burst?,Short increase in behavior during an extinction phase before the behavior is finally extinguished,ON,bl
What is resurgence?,"Imagine Behavior A is first learned then extinguished. Then, Behavior B is learned but also extinguished. As Behavior B becomes extinguished, there will be an increase in Behavior A (i.e., the old behavior returns).",ON,bl
"What did Capehart et al., (1958) discover with respect to the number of responses made during extinction?","These researchers found that if more force was required during the extinction phase, fewer responses were made.",ON,bl
What are the various components of a compound chaining schedule?,"Behavior can be reinforced using combinations of reinforcement schedules. For instance, an FR 10 FI 15'' VR 20 schedule would mean that the animal must first respond 10 times, after which the animal must respond once within a 15 second window, and finally the animal must respond with an average of 20 responses. This entire process would produce one food reward, and the entire process must be repeated to gain another food reward.",ON,bl
"What is the partial reinforcement effect (e.g., Mowrer and Jones, 1945)?","Mowrer and Jones compared reinforcement schedules in an extinction paradigm. They found that the more intermittent the reinforcement schedule, the longer it took to extinguish. In their experiment, the FR 4 paradigm elicited the most responses during extinction, whereas the FR 1 exhibited the fewest.",ON,bl
How is the partial reinforcement effect contradictory to the law of effect?,"The law of effect states that each time a behavior is followed by a satisfactory outcome, that behavior is further strengthened. However, the PRE finding suggests that the intermittent schedules of reinforcement are leading to more learning, making them harder to extinguish. But, according to the law of effect, the FR 1 schedule should be the most difficult to extinguish because it should have resulted in the most learning.",ON,bl
What is the discrimination hypothesis and how does it explain the partial reinforcement effect?,This hypothesis states that it is easier to detect the extinction phase with an FR 1 schedule versus an intermittent schedule. They keep responding during the extinction phase following an intermittent schedule because they are used to not getting reinforced after each response.,ON,bl
What is the response unit hypothesis and how does it explain the partial reinforcement effect?,"This hypothesis recharacterizes how we mathematically calculate the number of responses during the extinction phase. For instance, an FR 2 schedule is not ""press - no reward, press - reward"" but ""press-press-reward"". By dividing up the total number of responses into ""response units"", the entire pattern elicited by Mowrer and Jones changes, and the FR 1 schedule now elicited the most responses during extinction and the FR 4 schedule elicited the fewest.",ON,bl
What is the difference between positive and negative punishment?,"Positive punishment is adding an aversive stimulus (such as shock), whereas negative punishment is removing a pleasant stimulus (such as denying access to water).",ON,bl
What did Boe and Church (1967) discover with rats regarding contingent versus non-contingent shocks?,"Rats avoided pressing the lever if it resulted in shock , but continued pressing the lever if the shocks were delivered randomly.",ON,bl
"What did Azrin, Holz, and Hake (1963) discover regarding the reward/punishment ratio and pigeon behavior?","The more often the shocks followed the disc pecks, the less often the pigeons pecked at the disc during the VI 3' reinforcement schedule (with the FR-1 schedule resulting in the fewest pecks, the FR-100 in the next fewest pecks, then the FR-200, and so on).",ON,bl
"What did Camp et al., (1967) discover about rats receiving shocks after different delays following a lever press?","The longer the shocks were delayed following the lever press, the harder it was for the rats to associate their behavior of pressing the lever with receiving the shocks.",ON,bl
What is the two-process theory of negative reinforcement / punishment?,"States that punishment involves both a Pavlovian element (e.g., lever produces shock, so the lever is therefore a CS for shock and I will avoid going near the lever) and an operant element (e.g., pressing the lever produces shock, so therefore I will stop pressing the lever to avoid shock)",ON,bl
